% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gsoc2019.R
\name{aggregate_sentences}
\alias{aggregate_sentences}
\title{Aggregate sentiment on sentence level to document level}
\usage{
aggregate_sentences(sent, how = "proportional", do.ignoreZeros = TRUE,
  alphaExp = 0.1)
}
\arguments{
\item{sent}{A \code{sentiment} object created with \code{\link{compute_sentiment_by_sentence}}}

\item{how}{a single \code{character} vector defining how aggregation from sentence to document should be performed. For currently
available options on how aggregation can occur, see \code{\link{get_hows}()$docs}.}

\item{do.ignoreZeros}{a \code{logical} indicating whether zero sentiment values have to be ignored in the determination of
the document weights while aggregating across documents. By default \code{do.ignoreZeros = TRUE}, such that documents with
a raw sentiment score of zero or for which a given feature indicator is equal to zero are considered irrelevant.}

\item{alphaExp}{a single \code{integer} vector. A smoothing factor to calculate weights for, used if
\code{"exponential" \%in\% howDocs} or \code{"inverseExponential" \%in\% howDocs}. Value should be between 0 and 1
(both excluded); see \code{\link{weights_exponential}}.}
}
\value{
\code{sentiment} object, i.e., a \code{data.table} containing
the sentiment scores \code{data.table} with an \code{"id"}, a \code{"date"} and a \code{"word_count"} column,
and all lexicon--feature sentiment scores columns. A \code{sentiment} object can be used for aggregation into
time series with the \code{\link{aggregate.sentiment}} function.
}
\description{
Aggregate sentiment of sentence level to document level.
}
\details{
With this function, sentiment on sentence level, can be aggregated to document level so it can be used
in the \code{\link{aggregate.sentiment}} function. There are 5 weighting schemes that can be used:
equal weight, proportional, inverse proportional, exponential and inverse exponential.
}
\examples{
data("usnews", package = "sentometrics")
data("list_lexicons", package = "sentometrics")
data("list_valence_shifters", package = "sentometrics")

l1<- sento_lexicons(list_lexicons[c("LM_en", "HENRY_en")],
                     list_valence_shifters[["en"]][, c("x", "t")])

# from a sentocorpus object, unigrams approach
corpus <- sento_corpus(corpusdf = usnews)
corpusSample <- quanteda::corpus_sample(corpus, size = 200)
sent <- compute_sentiment_by_sentence(corpusSample, l1, how = "squareRootCounts")
agg_sent <- aggregate_sentences(sent, how="proportional")

}
\author{
Jeroen Van Pelt, Samuel Borms, Andres Algaba
}
