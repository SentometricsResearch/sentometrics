% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sentiment_engines.R
\name{aggregate_sentences}
\alias{aggregate_sentences}
\title{Aggregate sentiment on sentence level into document-level sentiment}
\usage{
aggregate_sentences(sentiment, how = "proportional",
  do.ignoreZeros = TRUE, alphaExp = 0.1)
}
\arguments{
\item{sentiment}{A \code{sentiment} object created with \code{\link{compute_sentiment}} and
\code{do.sentence = TRUE}.}

\item{how}{a single \code{character} vector defining how aggregation from sentence to document should be
performed. For currently available options on how aggregation can occur, see \code{\link{get_hows}()$docs}.}

\item{do.ignoreZeros}{a \code{logical} indicating whether zero sentiment values have to be ignored in the
determination of the sentence weights while aggregating across sentences. By default
\code{do.ignoreZeros = TRUE}, such that sentences with a raw sentiment score of zero or for which a given
feature indicator is equal to zero are considered irrelevant.}

\item{alphaExp}{a single \code{integer} vector as the weight smoothing factor, used if
\code{how == "exponential"} or \code{how == "inverseExponential"}. Value should be between 0 and 1
(both excluded); see \code{\link{weights_exponential}}.}
}
\value{
\code{sentiment} object with a \code{data.table} containing
the sentiment scores \code{data.table} with an \code{"id"}, a \code{"date"} and a \code{"word_count"} column,
and all lexicon--feature sentiment scores columns. A \code{sentiment} object can be used for aggregation into
time series with the \code{\link{aggregate.sentiment}} function.
}
\description{
Aggregate sentiment on sentence level into document-level sentiment.
}
\details{
This function aggregates sentiment on sentence level into document-level sentiment. It can then be
used in the \code{\link{aggregate.sentiment}} function.
}
\examples{
data("usnews", package = "sentometrics")
data("list_lexicons", package = "sentometrics")
data("list_valence_shifters", package = "sentometrics")

l <- sento_lexicons(list_lexicons[c("LM_en", "HENRY_en")],
                    list_valence_shifters[["en"]][, c("x", "t")])

# compute sentence-level sentiment
corpus <- sento_corpus(corpusdf = usnews)
corpusSample <- quanteda::corpus_sample(corpus, size = 200)
sent <- compute_sentiment(corpusSample, l, how = "squareRootCounts", do.sentence = TRUE)

# aggregate into document-level sentiment
sentAggDocs <- aggregate_sentences(sent, how = "proportional")

# further optional aggregation into time series
ctr <- ctr_agg(howTime = c("equal_weight", "linear"), by = "month", lag = 4)
sentomeasures <- aggregate(sentAggDocs, ctr)

}
\author{
Jeroen Van Pelt, Samuel Borms, Andres Algaba
}
