% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sentmeasures.R
\name{compute_sentiment}
\alias{compute_sentiment}
\title{Computation of document-level sentiment across features and lexicons}
\usage{
compute_sentiment(corpuS, lexicons, how = get_hows()$words)
}
\arguments{
\item{corpuS}{a \code{corpuS} object.}

\item{lexicons}{output from a \code{setup_lexicons()} call.}

\item{how}{a single character vector defining how aggregation within documents will be performed.
For currently available options on how aggregation can occer, access \code{get_hows()$words}.}
}
\value{
A list containing:
\item{corpuS}{the supplied \code{corpuS} object.}
\item{sent}{a sentiment scores \code{data.frame} with document ids, dates and features--lexicons sentiment scores columns.}
\item{features}{a character vector of the different features.}
\item{lexicons}{a character vector of the different lexicons used.}
}
\description{
Given a corpus of texts, computes sentiment per document starting from the bag-of-words approach,
based on the lexicons provided and a preferred aggregation across words per document scheme. Relies partly on
the \pkg{quanteda} package.
}
