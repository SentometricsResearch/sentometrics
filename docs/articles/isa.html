<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Intratextual Sentiment Analysis • sentometrics</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Intratextual Sentiment Analysis">
<meta property="og:description" content="sentometrics">
<meta property="og:image" content="https://sborms.github.io/sentometrics/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">sentometrics</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.8.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/sentometrics.html">Get started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Examples
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Tutorials</li>
    <li>
      <a href="../articles/corpus.html">Corpus manipulation</a>
    </li>
    <li>
      <a href="../articles/sentiment.html">Sentiment computation</a>
    </li>
    <li>
      <a href="../articles/indexation.html">Index aggregation</a>
    </li>
    <li>
      <a href="../articles/modeling.html">Modeling</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Applications</li>
    <li>
      <a href="../articles/epu.html">Creating EPU indices</a>
    </li>
    <li>
      <a href="../articles/vix.html">Predicting the VIX index</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Contributions
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/gopress.html">Analyzing Gopress data</a>
    </li>
  </ul>
</li>
<li>
  <a href="../articles/research.html">Research</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    News
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/development.html">Development</a>
    </li>
    <li>
      <a href="../news/index.html">Releases</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/sborms/sentometrics/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Intratextual Sentiment Analysis</h1>
                        <h4 class="author">Olivier Delmarcelle, Ghent University, VUB</h4>
            
            <h4 class="date">17/06/2020</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/sborms/sentometrics/blob/master/vignettes/isa.Rmd"><code>vignettes/isa.Rmd</code></a></small>
      <div class="hidden name"><code>isa.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>The <strong><code>sentometrics</code></strong> package introduces simple functions to quickly compute the sentiment of texts within a corpus. This easy-to-use approach does not prevent more advanced analysis, and the <strong><code>sentometrics</code></strong> functions remain a solid choice for cutting-edge research. This tutorial will present how to go beyond the basic <strong><code>sentometrics</code></strong> settings in order to analyse the intratextual sentiment structure of texts.</p>
<div id="intratextual-sentiment-structure" class="section level3">
<h3 class="hasAnchor">
<a href="#intratextual-sentiment-structure" class="anchor"></a>Intratextual Sentiment Structure</h3>
<p>Does the position of positive and negative words within a text matter? That’s a question investigated by <a href="https://doi.org/10.1111/fima.12219">Boudt &amp; Thewissen, 2019</a> during their research regarding sentiment implied by CEO letters. Based on a large dataset of letters, they analyze how sentiment-bearing words are positioned within the text. They find that CEOs tend to emphasize sentiment at the beginning and the end of their letter, in the hopes of leaving a positive impression to the reader.</p>
<p>Their results confirm generally accepted theories of linguistics saying that readers remember best the first (primacy effect) and the last (recency effect) portions of a text, and that the end of the text contributes the most to the reader’s final feeling.</p>
<p>One can wonder whether other types of texts follow a similar structure? Indeed, the world is full of different text media, from Twitter posts to news articles, and most of them are less cautiously written than CEO letters. Let’s investigate together one of these with the help of the <strong><code>sentometrics</code></strong> package!</p>
<!-- ### How to identify Intratextual Structure? -->
<!-- We will investigate two different methods to identify Intratextual structure within a corpus of text. A first method is to separate each document in equal-sized portions, called *bins*. Specific *bins* (e.g., the first *bin* of each document) can be aggregated across all document to identify a behaviour for this specific *bin*. Such measures can then be compared between discinct *bins* (e.g. the behaviour of the first *bin* against the behaviour of the last *bin*). The second method is to use the Herfindahl-Hirschman Index to compute the concentration of sentiments within texts. -->
<!-- The documents used in the following analysis are articles from popular newspapers from 1971 to the last decade.  -->
</div>
<div id="learning-outcomes" class="section level3">
<h3 class="hasAnchor">
<a href="#learning-outcomes" class="anchor"></a>Learning outcomes</h3>
<p>As part of this tutorial, you will learn how to:</p>
<ul>
<li>Decompose your texts into <em>bins</em> (equal-sized containers of words) or sentences.</li>
<li>Compute sentiments with a variety of weighting schemes.</li>
<li>Create and use your own weighting scheme for a classification task.</li>
</ul>
</div>
</div>
<div id="preparation" class="section level2">
<h2 class="hasAnchor">
<a href="#preparation" class="anchor"></a>Preparation</h2>
<p>Let’s load the required packages first.</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"rio"</span>)             <span class="co"># package for extracting data from GitHub</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"data.table"</span>)      <span class="co"># package bringing in the data.table machinery</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"quanteda"</span>)        <span class="co"># package useful for text and document manipulation</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"sentometrics"</span>)    <span class="co"># package containing sentiment computation tools</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"lexicon"</span>)         <span class="co"># package with multiple lexicons</span></pre></body></html></div>
<p>In this tutorial, we will use a slight variation from the built-in <code>usnews</code> object from the <strong><code>sentometrics</code></strong> package. We would like to compare our computed sentiment measure against some benchmark, but the built-in <code>usnews</code> does not include one. Fortunately, we processed a new dataset <code>usnews2</code> containing a benchmark just for you! It can be retrieved directly from GitHub using the <strong><code>rio</code></strong> package.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="no">usnews2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rio/man/import.html">import</a></span>(<span class="st">"https://raw.githubusercontent.com/odelmarcelle/public/master/usnews2/usnews2.RData"</span>)
<span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span>(<span class="no">usnews2</span>$<span class="no">s</span>)</pre></body></html></div>
<pre><code>## 
##  -1   1 
## 605 344</code></pre>
<p>The variable <code>s</code> indicates whether the news is more positive or negative, based on an expert’s opinion. We are going to try to predict this value at the end of the tutorial.</p>
<p>We can already prepare a <code>sento_corpus</code> and a <code>sento_lexicon</code> for our future sentiment computation. For the <code>sento_corpus</code>, we will also create a <code>dummyFeature</code> filled with 1’s. Since sentiment computations are multiplied by the features of a <code>sento_corpus</code>, we want this dummy feature to observe the whole corpus’s sentiments. This <code>dummyFeature</code> is created by default whenever there’s no feature at the creation of the <code>sento_corpus</code>.</p>
<p>Finally, we remove the feature <code>s</code> from the <code>sento_corpus</code>, as we do not need it for sentiment computation.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="no">usnews2Sento</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/sento_corpus.html">sento_corpus</a></span>(<span class="no">usnews2</span>) <span class="co"># note that the feature 's' is automatically re-scaled from {-1;1} to {0;1}</span>
<span class="no">usnews2Sento</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/add_features.html">add_features</a></span>(<span class="no">usnews2Sento</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw">dummyFeature</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">usnews2Sento</span>))))

<span class="fu"><a href="https://quanteda.io/reference/docvars.html">docvars</a></span>(<span class="no">usnews2Sento</span>, <span class="st">"s"</span>) <span class="kw">&lt;-</span> <span class="kw">NULL</span> <span class="co"># R-removing the feature</span></pre></body></html></div>
<p>We will use a single lexicon for this analysis, the combined Jockers &amp; Rinker lexicon, obtained from the <strong><code>lexicon</code></strong> package. However, we will prepare a second and different version of this lexicon where the sentiments assigned to words are all positive, regardless of their original signs. This second lexicon will be useful to better detect the sentiment intensity conveyed.</p>
<p>We used the <code>data.table</code> operator <code>[]</code> to create the second lexicon in a very efficient way. Most <strong><code>sentometrics</code></strong> objects are based on <code>data.table</code> and this allows to perform complex data transformations. If this is the first time you are seeing the <code>data.table</code> way of using <code>[]</code>, we recommend you to have a look at their <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html">Introduction vignette</a> and enjoy this powerful tool!</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">lex</span> <span class="kw">&lt;-</span> <span class="kw pkg">lexicon</span><span class="kw ns">::</span><span class="no"><a href="https://rdrr.io/pkg/lexicon/man/hash_sentiment_jockers_rinker.html">hash_sentiment_jockers_rinker</a></span>

<span class="no">sentoLexicon</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/sento_lexicons.html">sento_lexicons</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">baseLex</span> <span class="kw">=</span> <span class="no">lex</span>,
                                    <span class="kw">absoluteLex</span> <span class="kw">=</span> <span class="no">lex</span>[, <span class="fu">.</span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">x</span>, <span class="kw">y</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span>(<span class="no">y</span>))]))
<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentoLexicon</span>, <span class="no">head</span>)</pre></body></html></div>
<pre><code>## $baseLex
##              x     y
## 1:     abandon -0.75
## 2:   abandoned -0.50
## 3:   abandoner -0.25
## 4: abandonment -0.25
## 5:    abandons -1.00
## 6:    abducted -1.00
## 
## $absoluteLex
##              x    y
## 1:     abandon 0.75
## 2:   abandoned 0.50
## 3:   abandoner 0.25
## 4: abandonment 0.25
## 5:    abandons 1.00
## 6:    abducted 1.00</code></pre>
</div>
<div id="a-review-of-sentiment-computation-with-sentometrics" class="section level2">
<h2 class="hasAnchor">
<a href="#a-review-of-sentiment-computation-with-sentometrics" class="anchor"></a>A review of sentiment computation with <strong><code>sentometrics</code></strong>
</h2>
<p><code><a href="../reference/compute_sentiment.html">compute_sentiment()</a></code> is at the base of sentiment analysis with <strong><code>sentometrics</code></strong>. That’s also the function we are going to use to analyse intratextual sentiment. This requires, however, to play with the most advanced features of the function. Before doing that, let us review the different computation settings to really understand what’s going on.</p>
<div id="default-computation---from-words-to-document-sentiments" class="section level3">
<h3 class="hasAnchor">
<a href="#default-computation---from-words-to-document-sentiments" class="anchor"></a>Default computation - from words to document sentiments</h3>
<p>When using the default settings (i.e., only specifying the <code>how</code> argument), the sentiment for each word within a text will be determined according to the provided lexicons. These word sentiments are then aggregated using the method defined by the <code>how</code> argument, aggregating up to the document level to form a sentiment value for the document.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="no">sentiment</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">sentiment</span>)</pre></body></html></div>
<pre><code>##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        192          -0.010156250                0.10130208
## 2: 830981642 1971-08-04        243           0.036831276                0.08539095
## 3: 830981666 1971-08-24        326           0.007515337                0.03849693
## 4: 830981681 1972-01-28        158           0.025316456                0.09493671
## 5: 830981684 1973-02-15        174          -0.004022989                0.03160920
## 6: 830981702 1973-05-31        227           0.009251101                0.06784141</code></pre>
<p>In this case, the <code>how = "proportional"</code> simply sum words’ sentiments then divide it by the number of words in a document. The different settings for <code>how</code> can be accessed using the <code><a href="../reference/get_hows.html">get_hows()</a></code> function. We are going to present the use of a more complex setting at the end of this tutorial.</p>
</div>
<div id="setting-do-sentence-true---from-words-to-sentences-sentiments" class="section level3">
<h3 class="hasAnchor">
<a href="#setting-do-sentence-true---from-words-to-sentences-sentiments" class="anchor"></a>Setting <code>do.sentence = TRUE</code> - from words to sentences sentiments</h3>
<p>A drastic change in the behaviour of <code><a href="../reference/compute_sentiment.html">compute_sentiment()</a></code> can be induced by specifying <code>do.sentence = TRUE</code> in the function call. If true, the output of <code>compute_sentiment</code> will no longer return a sentiment value for each document, but each sentence. Sentiment values within each sentence are still computed using the method provided in the <code>how</code> argument, but the function stops there.</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="no">sentiment</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>, <span class="kw">do.sentence</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">sentiment</span>)</pre></body></html></div>
<pre><code>##           id sentence_id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632           1 1971-01-12         28           -0.09285714                0.12142857
## 2: 830981632           2 1971-01-12         37            0.01081081                0.01081081
## 3: 830981632           3 1971-01-12          6           -0.01666667                0.15000000
## 4: 830981632           4 1971-01-12         33            0.01666667                0.04696970
## 5: 830981632           5 1971-01-12         16           -0.04687500                0.07812500
## 6: 830981632           6 1971-01-12         24            0.04166667                0.06250000</code></pre>
<p>The new column <code>sentence_id</code> in the output is used to identify the sentences of a single document. This result can be used as-is for analysis at the sentence level, or sentences sentiments can be aggregated to obtain documents sentiments, as in the default setting. One way to aggregate sentences sentiments up to documents sentiments is to use the <code><a href="https://rdrr.io/r/stats/aggregate.html">aggregate()</a></code> method of <strong><code>sentometrics</code></strong>.</p>
</div>
<div id="trick-with-bins-in-a-list-do-sentence-and-tokens" class="section level3">
<h3 class="hasAnchor">
<a href="#trick-with-bins-in-a-list-do-sentence-and-tokens" class="anchor"></a>Trick with <em>bins</em> in a list, <code>do.sentence</code> and <code>tokens</code>
</h3>
<p>Analyzing the sentiment of individual sentences is already a nice approach to observe intra-document sentiment, but sometimes it is better to define a custom container for which sentiments are going to be computed. This is the approach used by <a href="https://doi.org/10.1111/fima.12219">Boudt &amp; Thewissen, 2019</a>, where they define <em>bins</em>, equal-sized containers of texts. The idea is to divide a document into equal-sized portion and to analyze each of them independently. Let’s say we decide to split a document of 200 words into 10 <em>bins</em>. To do so, we are going to store the first 20 words in the first <em>bin</em>, the words 21 to 40 in the second <em>bin</em>, and so on… This way, each <em>bin</em> will account for 10% of the text. By repeating the procedure for all texts of a corpus, we can easily compare specific text portions (e.g., the first 10%) between multiples documents.</p>
<p>Let’s split our documents into sets of <em>bins</em>. The first step is to obtain a vector of characters for each document. This is done easily with the <code>tokens</code> function from the <strong><code>quanteda</code></strong> (remember that <strong><code>sentometrics</code></strong> objects are also based on <strong><code>quanteda</code></strong>, letting us free to use most functions from this package).</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="no">usnews2Toks</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/tokens.html">tokens</a></span>(<span class="no">usnews2Sento</span>, <span class="kw">remove_punct</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">usnews2Toks</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://quanteda.io/reference/tokens_tolower.html">tokens_tolower</a></span>(<span class="no">usnews2Toks</span>)  <span class="co"># changing all letters to lowercase is optional but recommended</span></pre></body></html></div>
<p>We now have a list of character vectors, one for each document. The second step is to split each of these vectors into a list of vectors, one vector representing one <em>bin</em>. The final structure will look like:</p>
<ul>
<li>Document 1
<ul>
<li>
<em>Bin</em> 1: “word1”, “word2”, …</li>
<li>
<em>Bin</em> 2: “word1”, “word2”, …</li>
<li>…</li>
<li>
<em>Bin</em> K: “word1”, “word2”, …</li>
</ul>
</li>
<li>Document 2
<ul>
<li>
<em>Bin</em> 1: “word1”, “word2”, …</li>
<li>
<em>Bin</em> 2: “word1”, “word2”, …</li>
<li>…</li>
<li>
<em>Bin</em> K: “word1”, “word2”, …</li>
</ul>
</li>
<li>…</li>
</ul>
<p>This can be done with the help of the convenient function <code><a href="https://rdrr.io/r/parallel/splitIndices.html">parallel::splitIndices()</a></code>. Usually intended to split tasks in a parallel computing setup, this function does exactly what we need: it splits a vector <code>1:N</code> into a list of <code>k</code> vectors. We use it to split the indices of each character vector in <code>usnews2Toks</code>.</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="no">nBins</span> <span class="kw">&lt;-</span> <span class="fl">10</span>

<span class="no">usnews2Bins</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="fl">1</span>:<span class="no">nBins</span>)
<span class="kw">for</span>(<span class="no">i</span> <span class="kw">in</span> <span class="fl">1</span>:<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">usnews2Toks</span>)){
  <span class="no">usnews2Bins</span><span class="kw">[[</span><span class="no">i</span>]] <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="kw pkg">parallel</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/splitIndices.html">splitIndices</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">usnews2Toks</span><span class="kw">[[</span><span class="no">i</span>]]), <span class="no">nBins</span>), <span class="kw">function</span>(<span class="no">x</span>){<span class="no">usnews2Toks</span><span class="kw">[[</span><span class="no">i</span>]][<span class="no">x</span>]})
}
<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">usnews2Bins</span>) <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">usnews2Toks</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">usnews2Bins</span><span class="kw">[[</span><span class="fl">1</span>]], <span class="fl">2</span>)</pre></body></html></div>
<pre><code>## [[1]]
##  [1] "a"            "mild"         "stock"        "rally"        "fizzled"      "late"        
##  [7] "today"        "overwhelmed"  "by"           "computerized" "selling"      "strategies"  
## [13] "and"          "anxiety"      "that"         "has"          "afflicted"    "investors"   
## [19] "since"        "the"         
## 
## [[2]]
##  [1] "historic"  "market"    "collapse"  "exactly"   "six"       "months"    "ago"       "the"      
##  [9] "dow"       "jones"     "average"   "of"        "30"        "blue-chip" "stocks"    "up"       
## [17] "more"      "than"      "32"</code></pre>
<p>Looking good! The last step is now to get the sentiment value for each <em>bin</em>. Implementing this approach with <code><a href="../reference/compute_sentiment.html">compute_sentiment()</a></code> require a little ‘cheat’! We’re going to trick <code><a href="../reference/compute_sentiment.html">compute_sentiment()</a></code> into believing that <em>bins</em> are actually sentences. This is done using the <code>tokens</code> argument in the function call and passing to it the <code>usnews2Bins</code> object we just created. The function will treat each character vector in <code>usnews2Bins</code> as a sentence and compute sentiment for it.</p>
<div class="sourceCode" id="cb14"><html><body><pre class="r"><span class="no">sentiment</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>, <span class="kw">do.sentence</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                               <span class="kw">tokens</span> <span class="kw">=</span> <span class="no">usnews2Bins</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">sentiment</span>)</pre></body></html></div>
<pre><code>##           id sentence_id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632           1 1971-01-12         20           -0.11250000                0.11250000
## 2: 830981632           2 1971-01-12         19           -0.01842105                0.06052632
## 3: 830981632           3 1971-01-12         19            0.02105263                0.02105263
## 4: 830981632           4 1971-01-12         20            0.03500000                0.08500000
## 5: 830981632           5 1971-01-12         19           -0.01315789                0.03947368
## 6: 830981632           6 1971-01-12         19           -0.03947368                0.06578947</code></pre>
<p>In this case, the <code>sentence_id</code> simply refers to the number of the <em>bin</em>. Let’s now see what we can do with the <em>bins</em> we just computed.</p>
</div>
</div>
<div id="exposing-intratextual-sentiment-structure-with-bins" class="section level2">
<h2 class="hasAnchor">
<a href="#exposing-intratextual-sentiment-structure-with-bins" class="anchor"></a>Exposing Intratextual Sentiment Structure with <em>bins</em>
</h2>
<p>In their analysis of CEO letters, <a href="https://doi.org/10.1111/fima.12219">Boudt &amp; Thewissen, 2019</a> identified an intratextual sentiment structure: CEOs would deliberately emphasize sentiments at the beginning and end of the letter, and pay attention to leave out a positive message and the end. Our dataset of news articles is radically different from these letters so we don’t expect to find a similar structure. However, based on our knowledge of news, we can formulate a hypothesis: news articles tend to use strong sentiments in their headlines to attract readers’ eyes. Let’s investigate this using our <em>bins</em>!</p>
<div id="absolute-sentiment" class="section level3">
<h3 class="hasAnchor">
<a href="#absolute-sentiment" class="anchor"></a>Absolute sentiment</h3>
<p>We expect that the first <em>bin</em> in each article presents on average more sentiment than in the rest of the text. Since news can either be positive or negative, it will easier to identify sentiment intensity using the absolute value lexicon prepared earlier. This way, we avoid the cancelling effect between positive and negative sentiments. Simply plotting the mean sentiment values for each <em>bin</em> across documents can give us some insight on the intratextual structure. Once again, we rely on <code>data.table</code>’s <code>[]</code> operator to easily group sentiment values per <code>sentence_id</code> (remember, these represent the <em>bin</em> number!). In addition to this, a boxplot can be useful to ensure that the mean sentiments are not driven by extreme outliers.</p>
<div class="sourceCode" id="cb16"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span>(<span class="kw">mfrow</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>,<span class="fl">2</span>))
<span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span>(<span class="no">sentiment</span>[, <span class="fu">.</span>(<span class="kw">s</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="no">`absoluteLex--dummyFeature`</span>)), <span class="kw">by</span> <span class="kw">=</span> <span class="no">sentence_id</span>], <span class="kw">type</span> <span class="kw">=</span> <span class="st">"l"</span>,
     <span class="kw">ylab</span> <span class="kw">=</span> <span class="st">"Mean absolute sentiment"</span>, <span class="kw">xlab</span> <span class="kw">=</span> <span class="st">"Bin"</span>)
<span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html">boxplot</a></span>(<span class="no">sentiment</span>$<span class="no">`absoluteLex--dummyFeature`</span> ~ <span class="no">sentiment</span>$<span class="no">sentence_id</span>, <span class="kw">ylab</span> <span class="kw">=</span> <span class="st">"Absolute sentiment"</span>, <span class="kw">xlab</span> <span class="kw">=</span> <span class="st">"Bin"</span>,
        <span class="kw">outline</span> <span class="kw">=</span> <span class="fl">FALSE</span>, <span class="kw">range</span> <span class="kw">=</span> <span class="fl">0.5</span>)</pre></body></html></div>
<p><img src="isa_files/figure-html/unnamed-chunk-10-1.png" width="1152"></p>
<p>We can see that the first two <em>bins</em> of articles tend to show a larger absolute sentiment on average. This gives some credit to our initial hypothesis that news headlines contain more sentiment.</p>
</div>
<div id="herfindahl-hirschman-index" class="section level3">
<h3 class="hasAnchor">
<a href="#herfindahl-hirschman-index" class="anchor"></a>Herfindahl-Hirschman Index</h3>
<p>Another way to study the intratextual sentiment structure is to compute the Herfindahl-Hirschman Index across all documents. This is a popular index of concentration, mainly used in measuring competition between firms on a given market. A value close to 0 indicates large dispersion between <em>bins</em> while a value of 1 indicated that all sentiments are found in a single <em>bin</em>. The formula to compute the index of a single document is:</p>
<p><span class="math display">\[H = \sum_{b=1}^{B} s_b^2\]</span> where <span class="math inline">\(b\)</span> are <em>bin</em> indexes and <span class="math inline">\(s\)</span> the proportion of the document sentiment found in a single <em>bin</em>.</p>
<p>Using <code>data.table</code>, we can easily compute the index for the whole set of documents.</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="no">herfindahl</span> <span class="kw">&lt;-</span> <span class="no">sentiment</span>[, <span class="fu">.</span>(<span class="kw">s</span> <span class="kw">=</span> <span class="no">`absoluteLex--dummyFeature`</span>/<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">`absoluteLex--dummyFeature`</span>)), <span class="kw">by</span> <span class="kw">=</span> <span class="no">id</span>]
<span class="no">herfindahl</span> <span class="kw">&lt;-</span> <span class="no">herfindahl</span>[, <span class="fu">.</span>(<span class="kw">h</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">s</span>^<span class="fl">2</span>)), <span class="kw">by</span> <span class="kw">=</span> <span class="no">id</span>]
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="no">herfindahl</span>$<span class="no">h</span>)</pre></body></html></div>
<pre><code>## [1] 0.1445487</code></pre>
<p>A result that shows there is concentration toward some <em>bins</em>! Note that this result is heavily dependent on the number of <em>bins</em> considered. Only index values computed with the same number of <em>bins</em> should be compared. Let’s show the index’s value if sentiments were uniformly positioned within the text:</p>
<div class="sourceCode" id="cb19"><html><body><pre class="r"><span class="no">x</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/data.table.html">data.table</a></span>(<span class="kw">id</span> <span class="kw">=</span> <span class="no">sentiment</span>$<span class="no">id</span>, <span class="kw">s</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">sentiment</span>)))

<span class="no">herfindahl</span> <span class="kw">&lt;-</span> <span class="no">x</span>[, <span class="fu">.</span>(<span class="kw">s</span> <span class="kw">=</span> <span class="no">s</span>/<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">s</span>)), <span class="kw">by</span> <span class="kw">=</span> <span class="no">id</span>]
<span class="no">herfindahl</span> <span class="kw">&lt;-</span> <span class="no">herfindahl</span>[, <span class="fu">.</span>(<span class="kw">h</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">s</span>^<span class="fl">2</span>)), <span class="kw">by</span> <span class="kw">=</span> <span class="no">id</span>]
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>(<span class="no">herfindahl</span>$<span class="no">h</span>)</pre></body></html></div>
<pre><code>## [1] 0.1</code></pre>
</div>
</div>
<div id="computing-sentiment-with-different-weights" class="section level2">
<h2 class="hasAnchor">
<a href="#computing-sentiment-with-different-weights" class="anchor"></a>Computing sentiment with different weights</h2>
<p>The <strong><code>sentometrics</code></strong> comes with a lot of different weightings methods to compute sentiment and aggregate them into document sentiments or even time series. These weightings methods can be accessed with the functions <code>get_hows</code>.</p>
<div class="sourceCode" id="cb21"><html><body><pre class="r"><span class="fu"><a href="../reference/get_hows.html">get_hows</a></span>()</pre></body></html></div>
<pre><code>## $words
## [1] "counts"                 "proportional"           "proportionalPol"       
## [4] "proportionalSquareRoot" "UShaped"                "inverseUShaped"        
## [7] "exponential"            "inverseExponential"     "TFIDF"                 
## 
## $docs
## [1] "equal_weight"        "proportional"        "inverseProportional" "exponential"        
## [5] "inverseExponential" 
## 
## $time
## [1] "equal_weight" "almon"        "beta"         "linear"       "exponential"  "own"</code></pre>
<p>So far, we’ve been using the <code>proportional</code> method from the <code>$words</code> set. The <code>$words</code> set contains the valid options for the <code>hows</code> argument of <code><a href="../reference/compute_sentiment.html">compute_sentiment()</a></code>. The other two sets are used within the <code><a href="https://rdrr.io/r/stats/aggregate.html">aggregate()</a></code> function, to respectively aggregate sentences sentiment into documents or document sentiments into time series.</p>
<p>With our earlier computation of sentiments using <code>do.sentences = TRUE</code>, we computed sentiments for sentences and <em>bins</em>. Now, for our next application, we need to aggregate these sentences and <em>bins</em> sentiments into documents sentiments. One option is to <code><a href="https://rdrr.io/r/stats/aggregate.html">aggregate()</a></code> using one of the methods shown above. Note the use of <code>do.full = FALSE</code> to stop the aggregation at the document level (otherwise, it would directly aggregate up to a time series).</p>
<div class="sourceCode" id="cb23"><html><body><pre class="r"><span class="no">docsSentiment</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aggregate.html">aggregate</a></span>(<span class="no">sentiment</span>, <span class="fu"><a href="../reference/ctr_agg.html">ctr_agg</a></span>(<span class="kw">howDocs</span> <span class="kw">=</span> <span class="st">"equal_weight"</span>), <span class="kw">do.full</span> <span class="kw">=</span> <span class="fl">FALSE</span>)

<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">sentiment</span> <span class="kw">=</span> <span class="no">sentiment</span>, <span class="kw">docsSentiment</span> <span class="kw">=</span> <span class="no">docsSentiment</span>), <span class="no">head</span>)</pre></body></html></div>
<pre><code>## $sentiment
##           id sentence_id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632           1 1971-01-12         20           -0.11250000                0.11250000
## 2: 830981632           2 1971-01-12         19           -0.01842105                0.06052632
## 3: 830981632           3 1971-01-12         19            0.02105263                0.02105263
## 4: 830981632           4 1971-01-12         20            0.03500000                0.08500000
## 5: 830981632           5 1971-01-12         19           -0.01315789                0.03947368
## 6: 830981632           6 1971-01-12         19           -0.03947368                0.06578947
## 
## $docsSentiment
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        194          -0.010342105                0.10005263
## 2: 830981642 1971-08-04        243           0.040703704                0.08505000
## 3: 830981666 1971-08-24        336           0.008021390                0.04153298
## 4: 830981681 1972-01-28        167           0.025422794                0.09031250
## 5: 830981684 1973-02-15        181          -0.004239766                0.03386940
## 6: 830981702 1973-05-31        224           0.008366271                0.07360562</code></pre>
<p>But as we have seen, some <em>bins</em> are more likely to present strong sentiment values than other, notably the first <em>bin</em> containing the headline of a news article. In this case, an equal weighting between <em>bins</em> will give as much importance to the inflated headline as the rest of the text. Maybe would it better to give less importance to the first <em>bin</em> instead, which would then limit its effect on the final document sentiment?</p>
<div id="specifying-your-own-weights" class="section level3">
<h3 class="hasAnchor">
<a href="#specifying-your-own-weights" class="anchor"></a>Specifying your own weights</h3>
<p>This is exactly the situation where we would like to test a specific weighting scheme! Say that instead of giving 10% importance to each <em>bin</em> in the document sentiment computation, we would give only about 5% importance to the first one and share the rest between the remaining <em>bins</em>. Sadly, <strong><code>sentometrics</code></strong> does not directly provide us with the tool for this kind of computation, we will need to create our weighting scheme and aggregate by hands. Luckily, the use of <code>data.table</code> makes these customisations painless.</p>
<p>First, we define our customized weights for <em>bins</em>:</p>
<div class="sourceCode" id="cb25"><html><body><pre class="r"><span class="no">w</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>/(<span class="no">nBins</span>-<span class="fl">0.5</span>),<span class="no">nBins</span>)
<span class="no">w</span>[<span class="fl">1</span>] <span class="kw">&lt;-</span>  <span class="no">w</span>[<span class="fl">1</span>]*<span class="fl">0.5</span>

<span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">sum</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">w</span>), <span class="kw">w</span> <span class="kw">=</span> <span class="no">w</span>)</pre></body></html></div>
<pre><code>## $sum
## [1] 1
## 
## $w
##  [1] 0.05263158 0.10526316 0.10526316 0.10526316 0.10526316 0.10526316 0.10526316 0.10526316
##  [9] 0.10526316 0.10526316</code></pre>
<p>Second, we can create a function that will aggregate <em>bins</em> based on our customized weights. This is simply the sum of element-wise vector multiplications.</p>
<div class="sourceCode" id="cb27"><html><body><pre class="r"><span class="no">aggregate_bins</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">x</span>,<span class="no">w</span>){<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">x</span>*<span class="no">w</span>)}

<span class="fu">aggregate_bins</span>(<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>), <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0.5</span>, <span class="fl">0.25</span>, <span class="fl">0.25</span>))</pre></body></html></div>
<pre><code>## [1] 1.75</code></pre>
<p>Third, we need to aggregate by hand using this weighting scheme, taking advantage of <code>data.table</code> operations. Things are slightly more complex here. Let’s describe what this transformation does.</p>
<p>Since we’re aggregating for each document, we set <code>by = id</code>, this specifies the groups for the other operations. Since there’s only one <code>date</code> for each <code>id</code>, using <code>by = .(id, date)</code> simply keeps the <code>date</code> column in the output.</p>
<p>Concerning the intra-groups aggregation (i.e., aggregating the <em>bins</em> of each document), there are two operations to perform. On one hand, we compute the sum of <code>word_count</code> in each <em>bin</em>, to obtain the number of words in the document. On the other hand, we apply the function <code>aggregate_bins</code> to a number of columns. <code>.SD</code> is a special symbol of data.table that specify a subset on which an operation should be performed. In this case, the subset represented by <code>.SD</code> is simply the columns stored in <code>.SDcols</code>. In simple words, this will apply the <code>aggregate_bins</code> function to each column, starting from column 5 (since columns 1 to 4 are <code>id</code>, <code>date</code>, <code>sentence_id</code> and <code>word_counts</code>).</p>
<div class="sourceCode" id="cb29"><html><body><pre class="r"><span class="no">docsSentiment</span> <span class="kw">&lt;-</span> <span class="no">sentiment</span>[, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="kw">word_count</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">word_count</span>), <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">.SD</span>, <span class="no">aggregate_bins</span>, <span class="kw">w</span> <span class="kw">=</span> <span class="no">w</span>)),
                           <span class="kw">by</span> <span class="kw">=</span> <span class="fu">.</span>(<span class="no">id</span>, <span class="no">date</span>),
                           <span class="kw">.SDcols</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">sentiment</span>), -<span class="fl">4</span>)]

<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span>(<span class="no">docsSentiment</span>)</pre></body></html></div>
<pre><code>##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        194          -0.004965374                0.09939751
## 2: 830981642 1971-08-04        243           0.035614035                0.08657895
## 3: 830981666 1971-08-24        336           0.006670419                0.03841824
## 4: 830981681 1972-01-28        167           0.025212848                0.08732585
## 5: 830981684 1973-02-15        181          -0.002554632                0.03062481
## 6: 830981702 1973-05-31        224           0.004722280                0.06538382</code></pre>
<p>On top of that, the output of this transformation is still a correct <code>sentiment</code> object and can be used in other <strong><code>sentometrics</code></strong> applications!</p>
<div class="sourceCode" id="cb31"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span>(<span class="no">docsSentiment</span>)</pre></body></html></div>
<pre><code>## [1] "sentiment"  "data.table" "data.frame"</code></pre>
</div>
<div id="application-to-news-sentiment-prediction" class="section level3">
<h3 class="hasAnchor">
<a href="#application-to-news-sentiment-prediction" class="anchor"></a>Application to news sentiment prediction</h3>
<p>Let’s now put all of this in a concrete example. We’ve been using a modified dataset <code>usnews2</code> since the beginning because we wanted to have a variable identifying whether the document is positive or negative. Our goal is now to try to predict this value.</p>
<p>To do so, we will consider 4 different approaches, in the form of four different weighting methods. We will study which weighting is the best to predict document’s sentiments. The four weighting methods will be:</p>
<ul>
<li>The default weighting based on word frequencies, regardless of the position.</li>
<li>A U-shaped weighting of words, where words at the beginning or end of the text are given more weights.</li>
<li>A sentence-weighting, where word sentiments are proportionally weighted up to a sentence sentiment level, then sentences are aggregated with an equal weighting to obtain the document sentiment.</li>
<li>The <em>bin</em> based approach, where word sentiments are proportionally weighted up to a <em>bin</em> sentiment level, then <em>bins</em> are aggregated with our custom weights: the first <em>bin</em> given half the weight and the other <em>bins</em> sharing the rest.</li>
</ul>
<p>The U-shaped weighting is something we haven’t seen before. This is a weighting method for words as per <code>get_words()</code> that gives more weight to the beginning and end of a text. Its exact formulation can be found at the end of the <a href="https://doi.org/10.2139/ssrn.3067734">Sentometrics vignette</a>, along with the other available weighting. This weighting scheme can be visualized as follows:</p>
<div class="sourceCode" id="cb33"><html><body><pre class="r"><span class="no">Qd</span> <span class="kw">&lt;-</span> <span class="fl">200</span> <span class="co"># number of words in the documents</span>
<span class="no">i</span> <span class="kw">&lt;-</span> <span class="fl">1</span>:<span class="no">Qd</span>

<span class="no">ushape</span> <span class="kw">&lt;-</span> (<span class="no">i</span> - (<span class="no">Qd</span>+<span class="fl">1</span>)/<span class="fl">2</span> )^<span class="fl">2</span>
<span class="no">ushape</span> <span class="kw">&lt;-</span> <span class="no">ushape</span>/<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">ushape</span>)

<span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span>(<span class="no">ushape</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">'l'</span>, <span class="kw">ylab</span> <span class="kw">=</span> <span class="st">"Weight"</span>, <span class="kw">xlab</span> <span class="kw">=</span> <span class="st">"Word position index"</span>, <span class="kw">main</span> <span class="kw">=</span> <span class="st">"U-shaped weight scheme"</span>)</pre></body></html></div>
<p><img src="isa_files/figure-html/unnamed-chunk-19-1.png" width="700"></p>
<p>Let’s compute sentiments with the four different weighting schemes. We will store the results in a list, <code>sentimentValues</code>.</p>
<div class="sourceCode" id="cb34"><html><body><pre class="r"><span class="no">sentimentValues</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>()

<span class="no">sentimentValues</span>$<span class="no">default</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>)
<span class="no">sentimentValues</span>$<span class="no">uShaped</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"UShaped"</span>)
<span class="no">sentimentValues</span>$<span class="no">sentences</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>, <span class="kw">do.sentence</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">sentimentValues</span>$<span class="no">bins</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/compute_sentiment.html">compute_sentiment</a></span>(<span class="no">usnews2Sento</span>, <span class="no">sentoLexicon</span>, <span class="kw">tokens</span> <span class="kw">=</span> <span class="no">usnews2Bins</span>, <span class="kw">how</span> <span class="kw">=</span> <span class="st">"proportional"</span>,
                                          <span class="kw">do.sentence</span> <span class="kw">=</span> <span class="fl">TRUE</span>)

<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="no">head</span>, <span class="kw">n</span><span class="kw">=</span><span class="fl">3</span>)</pre></body></html></div>
<pre><code>## $default
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        192          -0.010156250                0.10130208
## 2: 830981642 1971-08-04        243           0.036831276                0.08539095
## 3: 830981666 1971-08-24        326           0.007515337                0.03849693
## 
## $uShaped
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        192         -0.0345837756                0.13075232
## 2: 830981642 1971-08-04        243          0.0264033780                0.09045472
## 3: 830981666 1971-08-24        326          0.0006524499                0.02734571
## 
## $sentences
##           id sentence_id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632           1 1971-01-12         28           -0.09285714                0.12142857
## 2: 830981632           2 1971-01-12         37            0.01081081                0.01081081
## 3: 830981632           3 1971-01-12          6           -0.01666667                0.15000000
## 
## $bins
##           id sentence_id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632           1 1971-01-12         20           -0.11250000                0.11250000
## 2: 830981632           2 1971-01-12         19           -0.01842105                0.06052632
## 3: 830981632           3 1971-01-12         19            0.02105263                0.02105263</code></pre>
<p>Before going further, we need to aggregate the two last results to a document level sentiment measure. We are going to aggregate sentences using the <code><a href="https://rdrr.io/r/stats/aggregate.html">aggregate()</a></code> function while we will repeat the same operation as before to compute the <em>bins</em> aggregation with the custom weights.</p>
<div class="sourceCode" id="cb36"><html><body><pre class="r"><span class="no">sentimentValues</span>$<span class="no">sentences</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/aggregate.html">aggregate</a></span>(<span class="no">sentimentValues</span>$<span class="no">sentences</span>, <span class="fu"><a href="../reference/ctr_agg.html">ctr_agg</a></span>(<span class="kw">howDocs</span> <span class="kw">=</span> <span class="st">"equal_weight"</span>), <span class="kw">do.full</span> <span class="kw">=</span> <span class="fl">FALSE</span>)

<span class="no">sentimentValues</span>$<span class="no">bins</span> <span class="kw">&lt;-</span> <span class="no">sentimentValues</span>$<span class="no">bins</span>[, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="kw">word_count</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">word_count</span>), <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">.SD</span>, <span class="no">aggregate_bins</span>, <span class="kw">w</span> <span class="kw">=</span> <span class="no">w</span>)),
                                             <span class="kw">by</span> <span class="kw">=</span> <span class="fu">.</span>(<span class="no">id</span>, <span class="no">date</span>),
                                             <span class="kw">.SDcols</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">sentiment</span>), -<span class="fl">4</span>)]

<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>[<span class="fl">3</span>:<span class="fl">4</span>], <span class="no">head</span>, <span class="kw">n</span><span class="kw">=</span><span class="fl">3</span>)</pre></body></html></div>
<pre><code>## $sentences
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        202          -0.016162828                0.11392764
## 2: 830981642 1971-08-04        251           0.049212232                0.09111569
## 3: 830981666 1971-08-24        349           0.009439859                0.04566347
## 
## $bins
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature
## 1: 830981632 1971-01-12        194          -0.004965374                0.09939751
## 2: 830981642 1971-08-04        243           0.035614035                0.08657895
## 3: 830981666 1971-08-24        336           0.006670419                0.03841824</code></pre>
<p>Finally, what remains to do is test our results against the variable <code>s</code> from <code>usnews2</code>. Since we know the number of positive and negative news in <code>s</code>, we can quickly and in a naive way measure the accuracy by ordering the documents by sentiment values.</p>
<div class="sourceCode" id="cb38"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span>(<span class="no">usnews2</span>$<span class="no">s</span>)</pre></body></html></div>
<pre><code>## 
##  -1   1 
## 605 344</code></pre>
<p>Thus, we classify the 605 documents with the lowest sentiment in each measure as negative, and the remaining documents as positive.</p>
<p>Let’s start by adding the <code>s</code> variable to the existing measures by merging each of them with <code>usnews2</code>. The use of <code>lapply</code> allows to do the operation of all measures at once.</p>
<div class="sourceCode" id="cb40"><html><body><pre class="r"><span class="no">sentimentValues</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="kw">function</span>(<span class="no">x</span>) <span class="fu"><a href="https://rdrr.io/r/base/merge.html">merge.data.frame</a></span>(<span class="no">x</span>, <span class="no">usnews2</span>[, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"id"</span>,<span class="st">"s"</span>)]))
<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="no">head</span>, <span class="kw">n</span> <span class="kw">=</span> <span class="fl">3</span>)</pre></body></html></div>
<pre><code>## $default
##          id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1 830981632 1971-01-12        192          -0.010156250                0.10130208 -1
## 2 830981642 1971-08-04        243           0.036831276                0.08539095 -1
## 3 830981666 1971-08-24        326           0.007515337                0.03849693  1
## 
## $uShaped
##          id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1 830981632 1971-01-12        192         -0.0345837756                0.13075232 -1
## 2 830981642 1971-08-04        243          0.0264033780                0.09045472 -1
## 3 830981666 1971-08-24        326          0.0006524499                0.02734571  1
## 
## $sentences
##          id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1 830981632 1971-01-12        202          -0.016162828                0.11392764 -1
## 2 830981642 1971-08-04        251           0.049212232                0.09111569 -1
## 3 830981666 1971-08-24        349           0.009439859                0.04566347  1
## 
## $bins
##          id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1 830981632 1971-01-12        194          -0.004965374                0.09939751 -1
## 2 830981642 1971-08-04        243           0.035614035                0.08657895 -1
## 3 830981666 1971-08-24        336           0.006670419                0.03841824  1</code></pre>
<p>Since we used <code>merge.data.frame</code>, we need to convert the objects back to <code>data.table</code> and then we can order each of these tables.</p>
<div class="sourceCode" id="cb42"><html><body><pre class="r"><span class="no">sentimentValues</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="no">as.data.table</span>) <span class="co"># converting back to data.table</span>

<span class="no">sentimentValues</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="kw">function</span>(<span class="no">x</span>) <span class="no">x</span>[<span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/setorder.html">order</a></span>(<span class="no">`baseLex--dummyFeature`</span>)]) <span class="co"># order based on the baseLex sentiment values</span>

<span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">sentimentValues</span>, <span class="no">head</span>, <span class="kw">n</span> <span class="kw">=</span> <span class="fl">3</span>)</pre></body></html></div>
<pre><code>## $default
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1: 830981961 1976-02-20        123           -0.06707317                0.10691057 -1
## 2: 842616972 2011-11-23        206           -0.05412621                0.12305825 -1
## 3: 842616769 2010-11-20        186           -0.05322581                0.08978495 -1
## 
## $uShaped
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1: 842613535 1991-05-02        213           -0.07650705                0.10549752  1
## 2: 830981961 1976-02-20        123           -0.07607828                0.09651269 -1
## 3: 842615597 2003-11-24        202           -0.07382476                0.10713842 -1
## 
## $sentences
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1: 830981961 1976-02-20        125           -0.07707298                0.12142702 -1
## 2: 830984376 1987-12-17        225           -0.06662902                0.10809238 -1
## 3: 842614104 1994-02-18        205           -0.06074249                0.09806308 -1
## 
## $bins
##           id       date word_count baseLex--dummyFeature absoluteLex--dummyFeature  s
## 1: 830981961 1976-02-20        127           -0.07186235                0.10620783 -1
## 2: 842616769 2010-11-20        186           -0.05663281                0.08476454 -1
## 3: 842616972 2011-11-23        208           -0.04818296                0.11309524 -1</code></pre>
<p>Finally, we compute the accuracy by counting the number of times the value of <code>s</code> is -1 in the first 605 documents and the number of time the value is 1 in the last 344 documents. We obtain a balanced accuracy measure by combining the true negative rate and the true positive rate.</p>
<div class="sourceCode" id="cb44"><html><body><pre class="r"><span class="no">index</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span>(<span class="no">usnews2</span>$<span class="no">s</span>)<span class="kw">[[</span><span class="fl">1</span>]]

<span class="no">rates</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="kw">trueNegativeRate</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span>(<span class="no">sentimentValues</span>, <span class="kw">function</span>(<span class="no">x</span>){<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">x</span>[<span class="fl">1</span>:<span class="no">index</span>, <span class="no">s</span> <span class="kw">==</span> -<span class="fl">1</span>]) / <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">x</span>[, <span class="no">s</span> <span class="kw">==</span> -<span class="fl">1</span>])}),
               <span class="kw">truePositiveRate</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span>(<span class="no">sentimentValues</span>, <span class="kw">function</span>(<span class="no">x</span>){<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">x</span>[(<span class="fl">1</span> + <span class="no">index</span>):<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">x</span>), <span class="no">s</span> <span class="kw">==</span> <span class="fl">1</span>]) / <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">x</span>[, <span class="no">s</span> <span class="kw">==</span> <span class="fl">1</span>])}))

<span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">rates</span>, <span class="kw">balancedAccuracy</span> <span class="kw">=</span> (<span class="no">rates</span>[,<span class="fl">1</span>] + <span class="no">rates</span>[,<span class="fl">2</span>]) / <span class="fl">2</span> )</pre></body></html></div>
<pre><code>##           trueNegativeRate truePositiveRate balancedAccuracy
## default          0.7256198        0.5174419        0.6215308
## uShaped          0.7289256        0.5232558        0.6260907
## sentences        0.7256198        0.5174419        0.6215308
## bins             0.7272727        0.5203488        0.6238108</code></pre>
<p>In this case, the U-shaped weighting performs best but we can already see the improvement brought by our custom weights in comparison with the default settings. In a supervised learning setting, it can be useful to optimize a custom weights scheme on a training dataset. An example of such a model can be found in the paper of <a href="https://doi.org/10.1111/fima.12219">Boudt &amp; Thewissen, 2019</a>, where <em>bins</em> weights are optimized to predict firm performance.</p>
<p>That’s the end of this tutorial. Want to go further? Have a try creating weird <em>bins</em>! They actually don’t have to be of equal size, their specification is up to anyone. Also, keep in mind that we have only covered news articles in this tutorial, which is not representative of all type of texts, feel free to investigate how sentiments are positioned within different types of documents.</p>
</div>
</div>
<div id="acknowledgements" class="section level2">
<h2 class="hasAnchor">
<a href="#acknowledgements" class="anchor"></a>Acknowledgements</h2>
<p>Thanks to Samuel Borms for providing a basis for this tutorial.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by <a href="https://www.linkedin.com/in/sam-borms">Samuel Borms</a>, <a href="https://ardiad.github.io/website">David Ardia</a>, <a href="https://www.kevenbluteau.com">Keven Bluteau</a>, <a href="https://linkedin.com/in/krisboudt">Kris Boudt</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '29d61aa2be101325ab9a82514b58064b',
    indexName: 'sentometrics',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
