
TO DO
-------------------------------------------------------------------------------

- write unit tests
- speeding up:
	> apply where for loops if desirable + optimal use of data.table and its methods
	> memory: rm() & gc()
	> Rcpp implementation of compute_df()
	> parallelization (internally + pointers in documentation on how to use)
- check warnings and sanity in caret::train() setup + parallelize
- check binomial and multinomial regressions
- plot function for sentomodeliter if logistic model (other type of plot or "link" predictions)
- finalize retrieve_attribution() (incl. documentation + attribution plotting)
- add IC/df estimator appropriate for logistic regression in elastic net-context (cf. Keven on GitHub)
- check perform_MCS()
- change dates in sentomodel object: c(first sample date, last sample date) [cf. attribution function]
- check ### in-code
- align code with GitHub margins
- add features based on if name is in texts (+ entity recognition vs. topic modelling)

(update to newest R version)
(check compatibility with major quanteda package update in October 2017)
(valence words not detected if first word is a valence shifter, e.g. " not " if text is "not ...")
(function to update sentomeasures [when new texts come in])
(simplify transition from corpora of other text mining packages to our's [cf. quanteda's conversion functions] + feature inclusion)
(interface with lexicon package for access to more lexicons)
(clean-up GitHub: separate Shiny app + delete irrelevant examples)



